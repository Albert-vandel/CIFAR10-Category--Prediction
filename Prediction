!pip install onnx seaborn  
import onnx # Explicitly import onnx
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
from torchvision.models import resnet18
import torch.onnx
from google.colab import files
from sklearn.metrics import confusion_matrix  # 新增
import seaborn as sns                          # 新增

# 1. 环境配置
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("使用设备:", device)

# 2. 数据加载与增强
transform_train = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(32, padding=4),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

trainset = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True, transform=transform_train)
trainloader = torch.utils.data.DataLoader(
    trainset, batch_size=128, shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(
    root='./data', train=False, download=True, transform=transform_test)
testloader = torch.utils.data.DataLoader(
    testset, batch_size=100, shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck')


# 新增混淆矩阵可视化函数
def plot_confusion_matrix(model, test_loader, class_names):
    model.eval()
    all_labels = []
    all_preds = []
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            all_labels.extend(labels.cpu().numpy())
            all_preds.extend(preds.cpu().numpy())
    
    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(12, 10))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", 
                xticklabels=class_names, yticklabels=class_names)
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.xticks(rotation=45)
    plt.yticks(rotation=0)
    plt.show()

# 新增样本预测热力图函数
def plot_sample_predictions(model, test_loader, class_names, num_samples=5):
    model.eval()
    images, labels = next(iter(test_loader))
    images = images[:num_samples].to(device)
    labels = labels[:num_samples]
    
    with torch.no_grad():
        outputs = model(images)
        probs = torch.nn.functional.softmax(outputs, dim=1).cpu().numpy()
    
    plt.figure(figsize=(15, 8))
    for i in range(num_samples):
        # 显示图像
        plt.subplot(2, num_samples, i+1)
        img = images[i].cpu().numpy().transpose((1, 2, 0))
        img = img * 0.5 + 0.5  # 反归一化
        plt.imshow(img)
        plt.title(f"True: {class_names[labels[i]]}")
        plt.axis("off")
        
        # 显示预测概率热力图
        plt.subplot(2, num_samples, num_samples+i+1)
        sns.heatmap(probs[i].reshape(1, -1), annot=True, cmap="YlGnBu",
                    cbar=False, xticklabels=class_names, yticklabels=False)
        plt.title("Predicted Probabilities")
        plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# 3. 模型定义
class LeNet(nn.Module):
    def __init__(self):
        super(LeNet, self).__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(3, 6, 5),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(6, 16, 5),
            nn.ReLU(),
            nn.MaxPool2d(2, 2)
        )
        self.fc = nn.Sequential(
            nn.Linear(16 * 5 * 5, 120),
            nn.ReLU(),
            nn.Linear(120, 84),
            nn.ReLU(),
            nn.Linear(84, 10)
        )

    def forward(self, x):
        x = self.cnn(x)
        x = x.view(x.size(0), -1)
        return self.fc(x)

def create_resnet():
    model = resnet18(pretrained=False)
    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
    model.fc = nn.Linear(model.fc.in_features, 10)
    return model

# 4. 训练函数（带可视化数据收集）
def train_model(model, name, num_epochs=15):
    model = model.to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    train_loss, train_acc = [], []
    val_loss, val_acc = [], []

    for epoch in range(num_epochs):
        # 训练阶段
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for inputs, labels in trainloader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

        epoch_loss = running_loss / len(trainloader)
        epoch_acc = 100 * correct / total
        train_loss.append(epoch_loss)
        train_acc.append(epoch_acc)

        # 验证阶段
        model.eval()
        val_running_loss = 0.0
        val_correct = 0
        val_total = 0

        with torch.no_grad():
            for inputs, labels in testloader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)

                val_running_loss += loss.item()
                _, predicted = outputs.max(1)
                val_total += labels.size(0)
                val_correct += predicted.eq(labels).sum().item()

        val_epoch_loss = val_running_loss / len(testloader)
        val_epoch_acc = 100 * val_correct / val_total
        val_loss.append(val_epoch_loss)
        val_acc.append(val_epoch_acc)

        print(f"{name} Epoch [{epoch+1}/{num_epochs}] "
              f"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}% | "
              f"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.2f}%")

    # 可视化训练过程
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(train_loss, label='Train Loss')
    plt.plot(val_loss, label='Val Loss')
    plt.title(f'{name} Loss Curve')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(train_acc, label='Train Acc')
    plt.plot(val_acc, label='Val Acc')
    plt.title(f'{name} Accuracy Curve')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.legend()

    plt.tight_layout()
    plt.show()

    return model, train_loss, train_acc, val_loss, val_acc  # Return necessary data

# 5. 训练并比较两个模型
print("训练LeNet...")
lenet = LeNet()
lenet, lenet_train_loss, lenet_train_acc, lenet_val_loss, lenet_val_acc = train_model(lenet, "LeNet")

print("\n训练ResNet...")
resnet = create_resnet()
resnet, resnet_train_loss, resnet_train_acc, resnet_val_loss, resnet_val_acc = train_model(resnet, "ResNet")

# 6. 可视化对比
def plot_compare(metric_name, lenet_data, resnet_data):
    plt.figure(figsize=(8, 5))
    plt.plot(lenet_data, label='LeNet')
    plt.plot(resnet_data, label='ResNet')
    plt.title(f'{metric_name} Comparison')
    plt.xlabel('Epoch')
    plt.ylabel(metric_name)
    plt.legend()
    plt.grid(True)
    plt.show()

# 比较验证准确率
plot_compare("Validation Accuracy", lenet_val_acc, resnet_val_acc)

# 比较验证损失
plot_compare("Validation Loss", lenet_val_loss, resnet_val_loss)

#导出混淆矩阵以及热力图
print("\n生成LeNet可视化:")
plot_confusion_matrix(lenet, testloader, classes)
plot_sample_predictions(lenet, testloader, classes)

print("\n生成ResNet可视化:")
plot_confusion_matrix(resnet, testloader, classes)
plot_sample_predictions(resnet, testloader, classes)

# 7. 模型导出与可视化 ================================
def export_to_onnx(model, model_name, input_size=(1, 3, 32, 32)):
    """
    导出PyTorch模型为ONNX格式
    参数：
        model : 训练好的模型实例
        model_name : 保存文件名（不带后缀）
        input_size : 输入张量维度（batch, channels, height, width）
    """
    # 生成虚拟输入
    dummy_input = torch.randn(input_size).to(device)

    # 设置保存路径
    onnx_path = f"{model_name}.onnx"

    # 导出模型
    torch.onnx.export(
        model,               # 要导出的模型
        dummy_input,         # 模型输入（随机生成）
        onnx_path,           # 保存路径
        export_params=True,  # 导出训练好的权重
        opset_version=12,    # ONNX算子版本
        do_constant_folding=True,  # 优化常量
        input_names=['input'],   # 输入节点名称
        output_names=['output'], # 输出节点名称
        dynamic_axes={      # 动态维度设置（支持可变batch）
            'input': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        }
    )
    print(f"✅ {model_name} 已成功导出为 {onnx_path}")
    return onnx_path

# 保存训练好的模型权重
torch.save(lenet.state_dict(), "lenet.pth")
torch.save(resnet.state_dict(), "resnet.pth")

# 导出两个模型
lenet_onnx = export_to_onnx(lenet, "lenet_cifar10")
resnet_onnx = export_to_onnx(resnet, "resnet18_cifar10")

# 保存到Google Drive
from google.colab import drive
drive.mount('/content/drive')
!cp *.onnx "/content/drive/MyDrive/Colab_Models/"
